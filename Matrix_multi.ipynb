{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSsdRr8Mk23y",
        "outputId": "abea6f8b-b51d-4de6-ecb4-3972d18cc300"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix Size: 64x64\n",
            "Time (Figure 4.16): 3.088e-05 seconds\n",
            "Time (Figure 4.3): 1.4368e-05 seconds\n",
            "\n",
            "Matrix Size: 128x128\n",
            "Time (Figure 4.16): 2.6464e-05 seconds\n",
            "Time (Figure 4.3): 3.072e-05 seconds\n",
            "\n",
            "Matrix Size: 256x256\n",
            "Time (Figure 4.16): 0.000110688 seconds\n",
            "Time (Figure 4.3): 0.000163936 seconds\n",
            "\n",
            "Matrix Size: 512x512\n",
            "Time (Figure 4.16): 0.000752128 seconds\n",
            "Time (Figure 4.3): 0.00114339 seconds\n",
            "\n",
            "Matrix Size: 1024x1024\n",
            "Time (Figure 4.16): 0.00580544 seconds\n",
            "Time (Figure 4.3): 0.00912774 seconds\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!nvcc -o ejecutable /content/matrix_multiplication.cu\n",
        "!./ejecutable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OU3v6gynqiv",
        "outputId": "233f0acf-a4c4-4b81-e15c-33e4b083f68b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-73x122tv\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-73x122tv\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 0a71d56e5dce3ff1f0dd2c47c29367629262f527\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4294 sha256=1870740d96a7392619c15c09400169af7dab1b7ff46319ad391268fe0d8567b1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zepr0lhl/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvnBJtRGnv7S",
        "outputId": "f9c02f92-116f-445e-f604-6863b7d269f9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <iostream>\n",
        "#include <cstdlib>\n",
        "#include <ctime>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "\n",
        "const int TILE_WIDTH = 16;  // Tamaño del bloque en las operaciones de matriz\n",
        "\n",
        "// Generar matriz aleatoria\n",
        "void generateRandomMatrix(float* matrix, int size) {\n",
        "    for (int i = 0; i < size; ++i) {\n",
        "        for (int j = 0; j < size; ++j) {\n",
        "            matrix[i * size + j] = static_cast<float>(rand()) / RAND_MAX;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "// FIGURE 4.16: A tiled Matrix Multiplication Kernel using shared memory\n",
        "__global__ void MatrixMulKernel_Figure4_16(float* M, float* N, float* P, int Width) {\n",
        "    __shared__ float Mds[TILE_WIDTH][TILE_WIDTH];\n",
        "    __shared__ float Nds[TILE_WIDTH][TILE_WIDTH];\n",
        "    int bx = blockIdx.x;\n",
        "    int by = blockIdx.y;\n",
        "    int tx = threadIdx.x;\n",
        "    int ty = threadIdx.y;\n",
        "\n",
        "    int Row = by * TILE_WIDTH + ty;\n",
        "    int Col = bx * TILE_WIDTH + tx;\n",
        "    float Pvalue = 0;\n",
        "\n",
        "    for (int ph = 0; ph < Width / TILE_WIDTH; ++ph) {\n",
        "        Mds[ty][tx] = M[Row * Width + ph * TILE_WIDTH + tx];\n",
        "        Nds[ty][tx] = N[(ph * TILE_WIDTH + ty) * Width + Col];\n",
        "        __syncthreads();\n",
        "\n",
        "        for (int k = 0; k < TILE_WIDTH; ++k) {\n",
        "            Pvalue += Mds[ty][k] * Nds[k][tx];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    P[Row * Width + Col] = Pvalue;\n",
        "}\n",
        "\n",
        "// FIGURE 4.3: A simple matrix multiplication kernel using one thread to compute one P element\n",
        "__global__ void MatrixMulKernel_Figure4_3(float* M, float* N, float* P, int Width) {\n",
        "    int Row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int Col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (Row < Width && Col < Width) {\n",
        "        float Pvalue = 0;\n",
        "\n",
        "        for (int k = 0; k < Width; ++k) {\n",
        "            Pvalue += M[Row * Width + k] * N[k * Width + Col];\n",
        "        }\n",
        "\n",
        "        P[Row * Width + Col] = Pvalue;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    // Configurar semilla aleatoria\n",
        "    srand(time(NULL));\n",
        "\n",
        "    // Tamaños de las matrices para probar\n",
        "    int matrixSizes[] = {64, 128, 256, 512, 1024};\n",
        "    int numSizes = sizeof(matrixSizes) / sizeof(matrixSizes[0]);\n",
        "\n",
        "    for (int i = 0; i < numSizes; ++i) {\n",
        "        int matrixSize = matrixSizes[i];\n",
        "\n",
        "        // Alojar memoria en el host (CPU)\n",
        "        float* hostMatrixA = new float[matrixSize * matrixSize];\n",
        "        float* hostMatrixB = new float[matrixSize * matrixSize];\n",
        "        float* hostResult = new float[matrixSize * matrixSize];\n",
        "\n",
        "        // Generar matrices aleatorias\n",
        "        generateRandomMatrix(hostMatrixA, matrixSize);\n",
        "        generateRandomMatrix(hostMatrixB, matrixSize);\n",
        "\n",
        "        // Alojar memoria en el dispositivo (GPU)\n",
        "        float* deviceMatrixA;\n",
        "        float* deviceMatrixB;\n",
        "        float* deviceResult;\n",
        "        cudaMalloc((void**)&deviceMatrixA, matrixSize * matrixSize * sizeof(float));\n",
        "        cudaMalloc((void**)&deviceMatrixB, matrixSize * matrixSize * sizeof(float));\n",
        "        cudaMalloc((void**)&deviceResult, matrixSize * matrixSize * sizeof(float));\n",
        "\n",
        "        // Copiar matrices del host al dispositivo\n",
        "        cudaMemcpy(deviceMatrixA, hostMatrixA, matrixSize * matrixSize * sizeof(float), cudaMemcpyHostToDevice);\n",
        "        cudaMemcpy(deviceMatrixB, hostMatrixB, matrixSize * matrixSize * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "        // Configurar dimensiones de bloque y de cuadrícula\n",
        "        dim3 threadsPerBlock(TILE_WIDTH, TILE_WIDTH);\n",
        "        dim3 numBlocks(matrixSize / TILE_WIDTH, matrixSize / TILE_WIDTH);\n",
        "\n",
        "        // Ejecutar y medir tiempo\n",
        "        cudaEvent_t start, stop;\n",
        "        cudaEventCreate(&start);\n",
        "        cudaEventCreate(&stop);\n",
        "\n",
        "\n",
        "        // Ejecutar y medir tiempo para FIGURE 4.16\n",
        "        cudaEventRecord(start);\n",
        "        MatrixMulKernel_Figure4_16<<<numBlocks, threadsPerBlock>>>(deviceMatrixA, deviceMatrixB, deviceResult, matrixSize);\n",
        "        cudaEventRecord(stop);\n",
        "        cudaEventSynchronize(stop);\n",
        "        float timeFigure4_16;\n",
        "        cudaEventElapsedTime(&timeFigure4_16, start, stop);\n",
        "\n",
        "        // Ejecutar y medir tiempo para FIGURE 4.3\n",
        "        cudaEventRecord(start);\n",
        "        MatrixMulKernel_Figure4_3<<<numBlocks, threadsPerBlock>>>(deviceMatrixA, deviceMatrixB, deviceResult, matrixSize);\n",
        "        cudaEventRecord(stop);\n",
        "        cudaEventSynchronize(stop);\n",
        "        float timeFigure4_3;\n",
        "        cudaEventElapsedTime(&timeFigure4_3, start, stop);\n",
        "\n",
        "        // Copiar resultado del dispositivo al host\n",
        "        cudaMemcpy(hostResult, deviceResult, matrixSize * matrixSize * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "        // Liberar memoria en el dispositivo\n",
        "        cudaFree(deviceMatrixA);\n",
        "        cudaFree(deviceMatrixB);\n",
        "        cudaFree(deviceResult);\n",
        "\n",
        "        // Calcular el tiempo de ejecución en segundos\n",
        "        float timeFigure4_16_sec = timeFigure4_16 / 1000.0;\n",
        "        float timeFigure4_3_sec = timeFigure4_3 / 1000.0;\n",
        "\n",
        "        // Imprimir resultados\n",
        "        std::cout << \"Matrix Size: \" << matrixSize << \"x\" << matrixSize << std::endl;\n",
        "        std::cout << \"Time (Figure 4.16): \" << timeFigure4_16_sec << \" seconds\" << std::endl;\n",
        "        std::cout << \"Time (Figure 4.3): \" << timeFigure4_3_sec << \" seconds\" << std::endl;\n",
        "        std::cout << std::endl;\n",
        "\n",
        "        // Liberar memoria en el host\n",
        "        delete[] hostMatrixA;\n",
        "        delete[] hostMatrixB;\n",
        "        delete[] hostResult;\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiMAmJkcm8R0",
        "outputId": "0e8d4fa4-0f7c-4e06-bf4e-55cd84b64804"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix Size: 64x64\n",
            "Time (Figure 4.16): 2.3136e-05 seconds\n",
            "Time (Figure 4.3): 1.2512e-05 seconds\n",
            "\n",
            "Matrix Size: 128x128\n",
            "Time (Figure 4.16): 2.2528e-05 seconds\n",
            "Time (Figure 4.3): 3.0528e-05 seconds\n",
            "\n",
            "Matrix Size: 256x256\n",
            "Time (Figure 4.16): 0.000112704 seconds\n",
            "Time (Figure 4.3): 0.000159776 seconds\n",
            "\n",
            "Matrix Size: 512x512\n",
            "Time (Figure 4.16): 0.000749728 seconds\n",
            "Time (Figure 4.3): 0.00114381 seconds\n",
            "\n",
            "Matrix Size: 1024x1024\n",
            "Time (Figure 4.16): 0.00580541 seconds\n",
            "Time (Figure 4.3): 0.00912182 seconds\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}